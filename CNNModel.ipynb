{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, GlobalMaxPooling1D, Embedding, Dropout\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_29664\\743087626.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  translated_rows['Statement'] = translated_rows['augmented_statement']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Sentiment_analysis_dataset.csv')\n",
    "df = df.dropna(subset=['Statement', 'Status'])\n",
    "df = df.drop(df[df.duplicated()][df[df.duplicated()]['Status'].isin(['Normal', 'Depression'])].index)\n",
    "def augment_text(text):\n",
    "    try:\n",
    "        blob = TextBlob(text)\n",
    "        translated = blob.translate(to='fr').translate(to='en')\n",
    "        return str(translated)\n",
    "    except Exception as e:\n",
    "        return text\n",
    "\n",
    "df['augmented_statement'] = df.apply(lambda row: augment_text(row['Statement'])\n",
    "                                     if row['Status'] in ['Anxiety', 'Stress','Bipolar','Personality disorder'] else None, axis=1)\n",
    "translated_rows = df[df['augmented_statement'].notna()]\n",
    "translated_rows['Statement'] = translated_rows['augmented_statement']\n",
    "\n",
    "df = pd.concat([df, translated_rows[['Statement', 'Status']]])\n",
    "\n",
    "df = df.drop(columns=['augmented_statement'])\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Lowercase text\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)  # Remove text in square brackets\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove links\n",
    "    text = re.sub(r'<.*?>+', '', text)  # Remove HTML tags\n",
    "    text = re.sub(r'[%s]' % re.escape(string.punctuation), '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\n', '', text)  # Remove newlines\n",
    "    text = re.sub(r'\\w*\\d\\w*', '', text)  # Remove words containing numbers\n",
    "    return text\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords_and_stem(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['Statement'] = df['Statement'].apply(lambda x: preprocess_text(x))\n",
    "df['Statement'] = df['Statement'].apply(lambda x: remove_stopwords_and_stem(x))\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['Status'] = label_encoder.fit_transform(df['Status'])\n",
    "\n",
    "X = df['Statement']\n",
    "y = df['Status']\n",
    "\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_padded = pad_sequences(X_seq, maxlen=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 14ms/step - accuracy: 0.5279 - loss: 1.2617 - val_accuracy: 0.7243 - val_loss: 0.7025\n",
      "Epoch 2/5\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 13ms/step - accuracy: 0.7677 - loss: 0.6280 - val_accuracy: 0.7850 - val_loss: 0.5744\n",
      "Epoch 3/5\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.8490 - loss: 0.4054 - val_accuracy: 0.8019 - val_loss: 0.5390\n",
      "Epoch 4/5\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9096 - loss: 0.2527 - val_accuracy: 0.7983 - val_loss: 0.5980\n",
      "Epoch 5/5\n",
      "\u001b[1m875/875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 0.9435 - loss: 0.1627 - val_accuracy: 0.8010 - val_loss: 0.6492\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Embedding(input_dim=10000, output_dim=128))  # Removed input_length\n",
    "cnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "cnn_model.add(GlobalMaxPooling1D())\n",
    "cnn_model.add(Dense(128, activation='relu'))\n",
    "cnn_model.add(Dropout(0.5))\n",
    "cnn_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = cnn_model.fit(X_train, y_train, epochs=5, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7971 - loss: 0.6407\n",
      "Test Accuracy: 0.7985143065452576\n",
      "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Accuracy Score:\n",
      "0.7985142857142857\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.92      0.91      1089\n",
      "           1       0.93      0.90      0.91       769\n",
      "           2       0.71      0.65      0.68      2150\n",
      "           3       0.90      0.91      0.91      2193\n",
      "           4       0.75      0.86      0.80       331\n",
      "           5       0.82      0.87      0.84       725\n",
      "           6       0.62      0.66      0.64      1493\n",
      "\n",
      "    accuracy                           0.80      8750\n",
      "   macro avg       0.81      0.82      0.81      8750\n",
      "weighted avg       0.80      0.80      0.80      8750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = cnn_model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = cnn_model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred_classes))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      "The predicted mental health status for the given text is: Depression\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "The predicted mental health status for the given text is: Normal\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
      "The predicted mental health status for the given text is: Anxiety\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "The predicted mental health status for the given text is: Suicidal\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "The predicted mental health status for the given text is: Normal\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
      "The predicted mental health status for the given text is: Bipolar\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "The predicted mental health status for the given text is: Normal\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "The predicted mental health status for the given text is: Suicidal\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "The predicted mental health status for the given text is: Normal\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "The predicted mental health status for the given text is: Suicidal\n"
     ]
    }
   ],
   "source": [
    "def predict_mental_health_status(text, max_len=100):\n",
    "    # Tokenize the input text (convert text to sequences of integers)\n",
    "    text_seq = tokenizer.texts_to_sequences([text])\n",
    "    \n",
    "    # Pad the sequences to ensure the input matches the expected input length\n",
    "    text_padded = pad_sequences(text_seq, maxlen=max_len)\n",
    "    \n",
    "    prediction = cnn_model.predict(text_padded)  \n",
    "    \n",
    "    # Get the class with the highest probability (index of the predicted class)\n",
    "    predicted_class_index = np.argmax(prediction, axis=1)[0] \n",
    "    \n",
    "    status = label_encoder.inverse_transform([predicted_class_index])\n",
    "    \n",
    "    return status[0]\n",
    "\n",
    "# Example usage\n",
    "text_1 = \"This is really getting out of control I feel exhausted from the constant voices in my head and my heart racing during social situations. I feel like everything I do, could have been done better, and that I am inadequate. My avoidance is getting worse to the point where I am unable to do anything at all. As a medical student, I chose to study this major without truly understanding the challenges that would come with it. Now, during my clinical rotations, every encounter with each patient feels like a nightmare. I constantly feel judged, and I fear harsh criticism is always one step away from being directed at me. This constant mental battle leaves me with no room to use the knowledge that I have worked so hard to achieve.\"\n",
    "result = predict_mental_health_status(text_1)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n",
    "\n",
    "text_2 = \"I am feeling great and excited about the future.\"\n",
    "result = predict_mental_health_status(text_2)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n",
    "\n",
    "text_3 = \"I am feeling very anxious and stressed about work.\"\n",
    "result = predict_mental_health_status(text_3)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n",
    "\n",
    "text_4 = \"I don't see a reason to continue living, I just wanna die.\"\n",
    "result = predict_mental_health_status(text_4)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n",
    "\n",
    "text_5 = \"I act impulsively and regret it later.\"\n",
    "result = predict_mental_health_status(text_5)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n",
    "\n",
    "text_6 = \"The problem is, the mistakes I’ve made are the kind I can’t fix because I won’t be on shift to address them. I’m not sure what to say to be helpful or to ease the tension. I honestly feel like all my coworkers hate me, just like everyone else has. Ive already had three panic attacks at work.\"\n",
    "result = predict_mental_health_status(text_6)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n",
    "\n",
    "text_7 = \"I’m feeling completely overwhelmed right now. The constant voices in my head and my racing heart in social situations are exhausting. It feels like everything I do could have been done better, and that I’m just not good enough. My avoidance is worsening to the point where I can hardly do anything at all. As a medical student, I chose this path without truly grasping the challenges it would bring. Now, during my clinical rotations, every interaction with a patient feels like a nightmare. I constantly feel judged, and I’m always afraid that harsh criticism is just around the corner. This ongoing mental struggle leaves me no space to fully apply the knowledge I’ve worked so hard to gain.\"\n",
    "result = predict_mental_health_status(text_7)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n",
    "\n",
    "text_8 = \"i dont want to live this life, i just want to lay down without thinking about this life\"\n",
    "result = predict_mental_health_status(text_8)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n",
    "\n",
    "text_9 = \"I really hate thinking about positive things and cant implement my ideas in real life\"\n",
    "result = predict_mental_health_status(text_9)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n",
    "\n",
    "text_10 = \"One moment, I feel on top of the world, full of energy and ideas, and the next, I'm completely drained and struggling to get out of bed.\"\n",
    "result = predict_mental_health_status(text_10)\n",
    "print(f\"The predicted mental health status for the given text is: {result}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
